{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiWulKAdmAHX"
      },
      "source": [
        "# Language processing & Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KsBGZpKkWki"
      },
      "source": [
        "음성 AI를 위한 자연어 처리와 Transformer의 핵심 구조인 Multi-head Attention을 구현하는 실습입니다.\n",
        "1. 텍스트 전처리 과정 이해\n",
        "    - tokenizing\n",
        "    - cleaning\n",
        "2. Multi-head attention 및 self-attention 구현.\n",
        "3. 각 과정에서 일어나는 연산과 input/output 형태 이해."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qRU5DFY2OM8"
      },
      "source": [
        "### 필요 패키지 install & import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wySpJEZWWU13",
        "outputId": "df2cc6c4-37d8-4e88-ca87-339e4b09bf3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from konlpy) (4.9.2)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.8/dist-packages (from konlpy) (1.22.4)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.6/465.6 KB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from JPype1>=0.7.0->konlpy) (23.0)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.1 konlpy-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install konlpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lDtMioSQQ1bB",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import torch\n",
        "import math\n",
        "\n",
        "from konlpy.tag import Okt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HH0VdC4uJJVG"
      },
      "source": [
        "## Req. 1-1 텍스트 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBiZObgRep_Q"
      },
      "source": [
        "주어진 문장 5개를 cleaning, tokenizing 한 뒤 정수 인코딩 하시오.  \n",
        "\n",
        "원하는 다른 tokenizer를 사용해도 좋습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "CnEIg_m6WU14"
      },
      "outputs": [],
      "source": [
        "sentences = [[\"안녕하세요 음성 AI 실!@습에 오신 것을 환영#$^&@$&$합니다.\"], [\"이네들은 7895435너무나 멀리 있습니다.\"], \n",
        "[\"계절이 지나가는 하늘에는가을로 가&^%@!$!^득 차 있습니다.\"], [\"아직 나의 청!@$!%춘이 다하지!@% 않은 까닭입니다.\"], [\"가슴 속에 하!@$나 둘 새겨지는 별을\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 정규표현식을 사용하여 숫자, 특수문자 제거"
      ],
      "metadata": {
        "id": "0gN3Ne8XaBn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_texts = []\n",
        "\n",
        "okt = Okt()\n",
        "\n",
        "punctuation = ['.']\n",
        "\n",
        "for sentence in sentences:\n",
        "    \n",
        "    s = sentence[0]\n",
        "\n",
        "    #문장에서 특수문자나 숫자를 매칭함\n",
        "    preprocessed_text = re.sub('[#$^&@!%0-9]','',s)\n",
        "\n",
        "    #okt 토크나이저로 문장 토큰화, 구두점 제거\n",
        "    tokenize_words = [word for word in okt.morphs(preprocessed_text) if word not in punctuation]\n",
        "\n",
        "    preprocessed_texts.append(tokenize_words)"
      ],
      "metadata": {
        "id": "K6NyxBchaAQ0"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Sfg-83vyJ4L",
        "outputId": "93d14575-cbbf-402b-ce82-b9064bcc74c7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['안녕하세요', '음성', 'AI', '실습', '에', '오신', '것', '을', '환영', '합니다'],\n",
              " ['이', '네', '들', '은', '너무나', '멀리', '있습니다'],\n",
              " ['계절', '이', '지나가는', '하늘', '에는', '가을로', '가득', '차', '있습니다'],\n",
              " ['아직', '나', '의', '청춘', '이', '다', '하지', '않은', '까닭', '입니다'],\n",
              " ['가슴', '속', '에', '하나', '둘', '새겨지는', '별', '을']]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "\n",
        "tokenizer.fit_on_texts(preprocessed_texts)"
      ],
      "metadata": {
        "id": "OfINhBWlxLvG"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2UAx3dQxbth",
        "outputId": "872ac303-1ce7-471e-d920-d24207808232"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'이': 1,\n",
              " '에': 2,\n",
              " '을': 3,\n",
              " '있습니다': 4,\n",
              " '안녕하세요': 5,\n",
              " '음성': 6,\n",
              " 'ai': 7,\n",
              " '실습': 8,\n",
              " '오신': 9,\n",
              " '것': 10,\n",
              " '환영': 11,\n",
              " '합니다': 12,\n",
              " '네': 13,\n",
              " '들': 14,\n",
              " '은': 15,\n",
              " '너무나': 16,\n",
              " '멀리': 17,\n",
              " '계절': 18,\n",
              " '지나가는': 19,\n",
              " '하늘': 20,\n",
              " '에는': 21,\n",
              " '가을로': 22,\n",
              " '가득': 23,\n",
              " '차': 24,\n",
              " '아직': 25,\n",
              " '나': 26,\n",
              " '의': 27,\n",
              " '청춘': 28,\n",
              " '다': 29,\n",
              " '하지': 30,\n",
              " '않은': 31,\n",
              " '까닭': 32,\n",
              " '입니다': 33,\n",
              " '가슴': 34,\n",
              " '속': 35,\n",
              " '하나': 36,\n",
              " '둘': 37,\n",
              " '새겨지는': 38,\n",
              " '별': 39}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoding_sentences = tokenizer.texts_to_sequences(preprocessed_texts)"
      ],
      "metadata": {
        "id": "xYpFpf0xz868"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QqUT8jO2pR6",
        "outputId": "2f324d58-23d6-4b30-e535-783dad79f345"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[5, 6, 7, 8, 2, 9, 10, 3, 11, 12],\n",
              " [1, 13, 14, 15, 16, 17, 4],\n",
              " [18, 1, 19, 20, 21, 22, 23, 24, 4],\n",
              " [25, 26, 27, 28, 1, 29, 30, 31, 32, 33],\n",
              " [34, 35, 2, 36, 37, 38, 39, 3]]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQj3ibkcWU15"
      },
      "source": [
        "결과는 다음과 같이 나와야 합니다.  \n",
        "\n",
        "\n",
        "[[5, 6, 7, 2, 8, 9, 3, 10, 11],  \n",
        " [1, 12, 13, 14, 15, 16, 4],  \n",
        " [17, 1, 18, 19, 20, 21, 22, 23, 4],  \n",
        " [24, 25, 26, 27, 1, 28, 29, 30, 31, 32],  \n",
        " [33, 34, 2, 35, 36, 37, 38, 3]]  \n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIyYvrZXWU15"
      },
      "source": [
        "## Req. 1-2 Multi-head self-attention 구조 익히기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgwQtMcRWU15"
      },
      "source": [
        "위에서 전처리한 데이터를 가져와 아래 과정을 실행하면서 시퀀스 입력이 multi-head self attention으로 어떻게 모델링 되는지 파악하시오."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "e9ULZIqTenSc",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "pad_id = 0\n",
        "vocab_size = 40\n",
        "\n",
        "data = encoding_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Hx3mcivgMyH",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# 길이 맞춰주기 위해 패딩합니다.\n",
        "def padding(data):\n",
        "  max_len = len(max(data, key=len))\n",
        "  print(f\"Maximum sequence length: {max_len}\")\n",
        "\n",
        "  for i, seq in enumerate(tqdm(data)):\n",
        "    if len(seq) < max_len:\n",
        "      data[i] = seq + [pad_id] * (max_len - len(seq))\n",
        "\n",
        "  return data, max_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3e8FiNvgX60",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "data, max_len = padding(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwPSIWYugaN0",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwqjACx8iidc"
      },
      "source": [
        "### Hyperparameter 세팅 및 embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-Ngp2nWimS8",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "d_model = 512  # model의 hidden size\n",
        "num_heads = 8  # head의 개수\n",
        "\n",
        "# d_model이 입력을 projection 시킬 임베딩 space의 차원이므로, num_heads로 나누어 떨어져야 한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJMi2Xsni5uq",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "embedding = nn.Embedding(vocab_size, d_model)\n",
        "\n",
        "# B: batch size, L: maximum sequence length\n",
        "batch = torch.LongTensor(data)  # (B, L)\n",
        "batch_emb = embedding(batch)  # (B, L, d_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tLCUQwojcUb",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "print(batch_emb)\n",
        "print(batch_emb.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0Lhx892gmi3"
      },
      "source": [
        "### Linear projection & 여러 head로 나누기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urXMBRnRgqvw"
      },
      "source": [
        "Multi-head attention 내에서 쓰이는 linear projection matrix들을 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DWKDqgCgfMk",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "w_q = nn.Linear(d_model, d_model)\n",
        "w_k = nn.Linear(d_model, d_model)\n",
        "w_v = nn.Linear(d_model, d_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcLuhda7m-Lm",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "w_0 = nn.Linear(d_model, d_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-vSL7PwnV6k",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "q = w_q(batch_emb)  # (B, L, d_model)\n",
        "k = w_k(batch_emb)  # (B, L, d_model)\n",
        "v = w_v(batch_emb)  # (B, L, d_model)\n",
        "\n",
        "print(q.shape)\n",
        "print(k.shape)\n",
        "print(v.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wnvlum-LnF1T"
      },
      "source": [
        "Q, k, v를 `num_head`개의 차원 분할된 여러 vector로 만듭니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXcYLZYvJT_1"
      },
      "source": [
        "- 이론적으로는 multi-head attention을 수행하면 input을 각각 다른 head 개수만큼의 Wq, Wk, Wv로 linear transformation 해서 각각 여러번의 attention 수행한 후 concat 한 후 linear transformation 수행해준다\n",
        "- 구현에서는 Wq, Wk, Wv 한 개씩\n",
        "- 실제 `attention is all you need` 논문의 구현 예시는 Query vector 한개를 dim으로 쪼개서 진행한다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tiOKAv9nEli",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "batch_size = q.shape[0]\n",
        "d_k = d_model // num_heads\n",
        "\n",
        "# num_heads * d_k로 쪼갠다\n",
        "q = q.view(batch_size, -1, num_heads, d_k)  # (B, L, num_heads, d_k)\n",
        "k = k.view(batch_size, -1, num_heads, d_k)  # (B, L, num_heads, d_k)\n",
        "v = v.view(batch_size, -1, num_heads, d_k)  # (B, L, num_heads, d_k)\n",
        "\n",
        "print(q.shape)\n",
        "print(k.shape)\n",
        "print(v.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tNb2isfn5Cx",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# num_heads를 밖으로 뺌으로써\n",
        "# 각 head가 (L, d_k) 만큼의 matrix를 가지고 self-attention 수행\n",
        "\n",
        "q = q.transpose(1, 2)  # (B, num_heads, L, d_k)\n",
        "k = k.transpose(1, 2)  # (B, num_heads, L, d_k)\n",
        "v = v.transpose(1, 2)  # (B, num_heads, L, d_k)\n",
        "\n",
        "print(q.shape)\n",
        "print(k.shape)\n",
        "print(v.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWrDA5_Sofad"
      },
      "source": [
        "### Scaled dot-product self-attention 구현"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w52C4k3Wfl8m"
      },
      "source": [
        "각 head에서 실행되는 self-attetion 과정입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5waKr0Hfi2K",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# shape - (L, L)\n",
        "# 같은 sequence 내에 서로 다른 token들에게 얼마나 가중치를 두고 attention을 해야하는가\n",
        "attn_scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)  # (B, num_heads, L, L)\n",
        "# softmax - row-wise이기 때문에 dim은 -1\n",
        "attn_dists = F.softmax(attn_scores, dim=-1)  # (B, num_heads, L, L)\n",
        "\n",
        "print(attn_dists)\n",
        "print(attn_dists.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7megouWpgCck",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "attn_values = torch.matmul(attn_dists, v)  # (B, num_heads, L, d_k)\n",
        "\n",
        "print(attn_values.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmSTaymdg-P_"
      },
      "source": [
        "### 각 head의 결과물 병합"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSdQZCk0hCNd"
      },
      "source": [
        "각 head의 결과물을 concat하고 동일 차원으로 linear projection합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaK0bpMGhQZ2",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "attn_values = attn_values.transpose(1, 2)  # (B, L, num_heads, d_k)\n",
        "attn_values = attn_values.contiguous().view(batch_size, -1, d_model)  # (B, L, d_model)\n",
        "\n",
        "print(attn_values.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTng_2SXhdH1",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# w_0 : (d_model, d_model)\n",
        "# 서로 다른 의미로 foucsing 된 각 head의 self-attention 정보들을 합쳐주는 역할 수행\n",
        "outputs = w_0(attn_values)\n",
        "\n",
        "print(outputs)\n",
        "print(outputs.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goX70VKqhxQH"
      },
      "source": [
        "## Req. 1-3 Multi-head self-attention 모듈 클래스 구현"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtNyV7mMj7V_"
      },
      "source": [
        "위의 과정을 모두 합쳐 하나의 Multi-head attention 모듈 class를 구현하겠습니다.\n",
        "\n",
        "아래 코드의 TODO 부분을 채워주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_kNhOTrkBHm",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "class MultiheadAttention(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MultiheadAttention, self).__init__()\n",
        "\n",
        "    # Q, K, V learnable matrices\n",
        "    self.w_q = nn.Linear(d_model, d_model)\n",
        "    self.w_k = nn.Linear(d_model, d_model)\n",
        "    self.w_v = nn.Linear(d_model, d_model)\n",
        "\n",
        "    # Linear projection for concatenated outputs\n",
        "    self.w_0 = nn.Linear(d_model, d_model)\n",
        "\n",
        "  # scaled-dot product attention\n",
        "  def self_attention(self, q, k, v):\n",
        "    attn_scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)  # (B, num_heads, L, L)\n",
        "    attn_dists = F.softmax(attn_scores, dim=-1)  # (B, num_heads, L, L)\n",
        "\n",
        "    attn_values = torch.matmul(attn_dists, v)  # (B, num_heads, L, d_k)\n",
        "\n",
        "    return attn_values\n",
        "\n",
        "  def forward(self, q, k, v):\n",
        "    batch_size = q.shape[0]\n",
        "\n",
        "    # linear projection\n",
        "    ################################################################################\n",
        "    # TODO 1: Implement the forward pass for linear projection.                #\n",
        "    ################################################################################\n",
        "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "    # head만큼 쪼개준다\n",
        "    ################################################################################\n",
        "    # TODO 2: Implement the forward pass for \bsplit head.                #\n",
        "    ################################################################################\n",
        "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "    # 각 head가 (L, d_k)의 matrix를 담당하도록 만든다\n",
        "    q = q.transpose(1, 2)  # (B, num_heads, L, d_k)\n",
        "    k = k.transpose(1, 2)  # (B, num_heads, L, d_k)\n",
        "    v = v.transpose(1, 2)  # (B, num_heads, L, d_k)\n",
        "\n",
        "    attn_values = self.self_attention(q, k, v)  # (B, num_heads, L, d_k)\n",
        "    attn_values = attn_values.transpose(1, 2).contiguous().view(batch_size, -1, d_model)  # (B, L, num_heads, d_k) => (B, L, d_model)\n",
        "\n",
        "    return self.w_0(attn_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYLuu_9alQxT",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "multihead_attn = MultiheadAttention()\n",
        "\n",
        "outputs = multihead_attn(batch_emb, batch_emb, batch_emb)  # (B, L, d_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMiXlYjSlTfB",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "print(outputs)\n",
        "print(outputs.shape)  # (batch_size, length, d_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTku1fySVR3L",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}